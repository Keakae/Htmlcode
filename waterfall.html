<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebGPU Spectral Waterfall with Microphone</title>
    <style>
        canvas {
            width: 100%;
            height: 300px;
            background-color: #000;
        }
        #status {
            font-size: 20px;
            color: green;
            text-align: center;
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <h1>WebGPU Spectral Waterfall with Microphone</h1>
    <canvas id="gpuCanvas" width="640" height="480"></canvas>
    <div id="status">Microphone Status: Not working</div>

    <!-- Подключаем eruda для отладки -->
    <script src="https://cdn.jsdelivr.net/npm/eruda"></script>
    <script>eruda.init();</script>

    <script type="module">
        async function initWebGPU() {
            if (!navigator.gpu) {
                console.error('WebGPU не поддерживается!');
                document.getElementById('status').innerText = 'WebGPU не поддерживается!';
                return;
            }

            const adapter = await navigator.gpu.requestAdapter();
            if (!adapter) {
                throw new Error('WebGPU адаптер не найден.');
            }

            const device = await adapter.requestDevice();
            if (!device) {
                throw new Error('WebGPU устройство не найдено.');
            }

            const canvas = document.getElementById('gpuCanvas');
            const context = canvas.getContext('webgpu');
            if (!context) {
                throw new Error('WebGPU контекст не получен.');
            }

            const format = navigator.gpu.getPreferredCanvasFormat();
            context.configure({
                device: device,
                format: format
            });

            // Вершинный шейдер
            const vertexShaderCode = `
            @vertex
            fn main(@builtin(vertex_index) VertexIndex: u32) -> @builtin(position) vec4<f32> {
                var positions = array<vec2<f32>, 4>(
                    vec2<f32>(-1.0, -1.0),
                    vec2<f32>( 1.0, -1.0),
                    vec2<f32>(-1.0,  1.0),
                    vec2<f32>( 1.0,  1.0)
                );
                let pos = positions[VertexIndex];
                return vec4<f32>(pos, 0.0, 1.0);
            }`;

            // Фрагментный шейдер
            const fragmentShaderCode = `
            @group(0) @binding(0) var<uniform> fftData: array<f32, 1024>;

            @fragment
            fn main(@builtin(position) fragCoord: vec4<f32>) -> @location(0) vec4<f32> {
                let index = i32(fragCoord.x / 640.0 * 1024.0);  // Масштабируем координаты под буфер FFT
                let amplitude = fftData[index];
                let color = vec4<f32>(amplitude, 0.0, 1.0 - amplitude, 1.0);
                return color;
            }`;

            const vertexModule = device.createShaderModule({ code: vertexShaderCode });
            const fragmentModule = device.createShaderModule({ code: fragmentShaderCode });

            const pipeline = device.createRenderPipeline({
                layout: 'auto',
                vertex: {
                    module: vertexModule,
                    entryPoint: 'main',
                    buffers: []
                },
                fragment: {
                    module: fragmentModule,
                    entryPoint: 'main',
                    targets: [{ format: format }]
                },
                primitive: {
                    topology: 'triangle-strip',
                    cullMode: 'none'
                }
            });

            // Буфер для данных FFT
            const fftBuffer = device.createBuffer({
                size: 1024 * 4, // 1024 значений, по 4 байта на значение (32-бит float)
                usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
            });

            const bindGroup = device.createBindGroup({
                layout: pipeline.getBindGroupLayout(0),
                entries: [{
                    binding: 0,
                    resource: {
                        buffer: fftBuffer
                    }
                }]
            });

            // Работа с микрофоном и анализ звука
            navigator.mediaDevices.getUserMedia({ audio: true, video: false })
                .then(function (stream) {
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = audioContext.createMediaStreamSource(stream);
                    const analyser = audioContext.createAnalyser();
                    analyser.fftSize = 2048;  // Устанавливаем размер FFT
                    const bufferLength = analyser.frequencyBinCount;  // Половина fftSize
                    const dataArray = new Uint8Array(bufferLength);

                    source.connect(analyser);
                    document.getElementById('status').innerHTML = 'Microphone Status: Working';

                    function render() {
                        analyser.getByteFrequencyData(dataArray);

                        // Конвертируем данные для передачи на GPU
                        const floatArray = new Float32Array(1024);
                        for (let i = 0; i < 1024; i++) {
                            floatArray[i] = dataArray[i] / 255.0;  // Нормализация значений
                        }

                        // Записываем данные в буфер GPU
                        device.queue.writeBuffer(fftBuffer, 0, floatArray.buffer, 0, floatArray.byteLength);

                        const commandEncoder = device.createCommandEncoder();
                        const textureView = context.getCurrentTexture().createView();

                        const renderPassDescriptor = {
                            colorAttachments: [{
                                view: textureView,
                                loadOp: 'clear',
                                clearValue: { r: 0.0, g: 0.0, b: 0.0, a: 1.0 },
                                storeOp: 'store',
                            }]
                        };

                        const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);
                        passEncoder.setPipeline(pipeline);
                        passEncoder.setBindGroup(0, bindGroup);
                        passEncoder.draw(4, 1, 0, 0);
                        passEncoder.end();

                        device.queue.submit([commandEncoder.finish()]);

                        requestAnimationFrame(render);  // Зацикливаем рендер
                    }

                    requestAnimationFrame(render);
                })
                .catch(function (err) {
                    console.error('Ошибка доступа к микрофону: ', err);
                    document.getElementById('status').innerText = 'Ошибка доступа к микрофону';
                });
        }

        initWebGPU();
    </script>
</body>
</html>
